{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CLASIFICACION DE BANANAS CON CNN\n",
                "\n",
                "## Estructura del proyecto:\n",
                "- **PARTE A**: Modelo entrenado desde cero\n",
                "- **PARTE B**: Transfer Learning con ResNet18\n",
                "- **PARTE C**: Comparacion y reproducibilidad\n",
                "\n",
                "**Dataset**: Fotos de bananas tomadas por mi\n",
                "- DAÑADO: 26 imagenes\n",
                "- MUY DAÑADO: 26 imagenes\n",
                "- NORMAL: 26 imagenes"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Importamos las librerias"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader, random_split\n",
                "from torchvision import datasets, transforms, models\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import random\n",
                "\n",
                "# Vemos si hay GPU disponible\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Usando: {device}\")\n",
                "\n",
                "# Ruta de mis imagenes\n",
                "RUTA_DATOS = r\"C:\\Users\\RubenC\\Documents\\aa6_RC\\FOTO BANANA\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PARTE A: MODELO CNN DESDE CERO\n",
                "\n",
                "**Contenido:**\n",
                "1. Modelo base: CNN simple con 2 bloques Conv->ReLU->MaxPool + capa densa\n",
                "2. Entrenamiento desde cero con mi dataset de bananas\n",
                "3. Experimentacion con hiperparametros (learning rate, batch size)\n",
                "4. Registro de curvas de perdida y accuracy"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Funcion para fijar la semilla (reproducibilidad)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def fijar_semilla(semilla):\n",
                "    random.seed(semilla)\n",
                "    np.random.seed(semilla)\n",
                "    torch.manual_seed(semilla)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Creamos nuestra CNN simple"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class MiCNN(nn.Module):\n",
                "    def __init__(self, num_clases=3):\n",
                "        super(MiCNN, self).__init__()\n",
                "        \n",
                "        # Bloque 1: Convolucion + ReLU + MaxPool\n",
                "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
                "        self.relu1 = nn.ReLU()\n",
                "        self.pool1 = nn.MaxPool2d(2, 2)\n",
                "        \n",
                "        # Bloque 2: Convolucion + ReLU + MaxPool\n",
                "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
                "        self.relu2 = nn.ReLU()\n",
                "        self.pool2 = nn.MaxPool2d(2, 2)\n",
                "        \n",
                "        # Capa final densa para clasificar\n",
                "        self.flatten = nn.Flatten()\n",
                "        self.fc1 = nn.Linear(64 * 16 * 16, 128)\n",
                "        self.relu3 = nn.ReLU()\n",
                "        self.fc2 = nn.Linear(128, num_clases)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        # Pasamos por bloque 1\n",
                "        x = self.conv1(x)\n",
                "        x = self.relu1(x)\n",
                "        x = self.pool1(x)\n",
                "        \n",
                "        # Pasamos por bloque 2\n",
                "        x = self.conv2(x)\n",
                "        x = self.relu2(x)\n",
                "        x = self.pool2(x)\n",
                "        \n",
                "        # Clasificacion\n",
                "        x = self.flatten(x)\n",
                "        x = self.fc1(x)\n",
                "        x = self.relu3(x)\n",
                "        x = self.fc2(x)\n",
                "        return x"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Funcion para cargar los datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def cargar_datos(batch_size, semilla=42):\n",
                "    fijar_semilla(semilla)\n",
                "    \n",
                "    # Transformaciones basicas\n",
                "    transformacion = transforms.Compose([\n",
                "        transforms.Resize((64, 64)),\n",
                "        transforms.ToTensor(),\n",
                "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "    ])\n",
                "    \n",
                "    # Cargamos el dataset\n",
                "    dataset = datasets.ImageFolder(RUTA_DATOS, transform=transformacion)\n",
                "    \n",
                "    # Dividimos 70% train, 30% validacion\n",
                "    tam_train = int(0.7 * len(dataset))\n",
                "    tam_val = len(dataset) - tam_train\n",
                "    \n",
                "    train_set, val_set = random_split(dataset, [tam_train, tam_val])\n",
                "    \n",
                "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
                "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
                "    \n",
                "    print(f\"Clases: {dataset.classes}\")\n",
                "    print(f\"Total: {len(dataset)} imagenes\")\n",
                "    print(f\"Train: {tam_train}, Val: {tam_val}\")\n",
                "    \n",
                "    return train_loader, val_loader, len(dataset.classes)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Funcion de entrenamiento"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def entrenar(modelo, train_loader, val_loader, epochs, lr):\n",
                "    criterio = nn.CrossEntropyLoss()\n",
                "    optimizador = optim.Adam(modelo.parameters(), lr=lr)\n",
                "    \n",
                "    # Listas para guardar el historial\n",
                "    hist_train_loss = []\n",
                "    hist_val_loss = []\n",
                "    hist_train_acc = []\n",
                "    hist_val_acc = []\n",
                "    \n",
                "    for epoch in range(epochs):\n",
                "        # Entrenamiento\n",
                "        modelo.train()\n",
                "        train_loss = 0\n",
                "        correctos = 0\n",
                "        total = 0\n",
                "        \n",
                "        for imgs, labels in train_loader:\n",
                "            imgs, labels = imgs.to(device), labels.to(device)\n",
                "            \n",
                "            optimizador.zero_grad()\n",
                "            salidas = modelo(imgs)\n",
                "            loss = criterio(salidas, labels)\n",
                "            loss.backward()\n",
                "            optimizador.step()\n",
                "            \n",
                "            train_loss += loss.item()\n",
                "            _, pred = torch.max(salidas, 1)\n",
                "            correctos += (pred == labels).sum().item()\n",
                "            total += labels.size(0)\n",
                "        \n",
                "        train_loss = train_loss / len(train_loader)\n",
                "        train_acc = 100 * correctos / total\n",
                "        \n",
                "        # Validacion\n",
                "        modelo.eval()\n",
                "        val_loss = 0\n",
                "        correctos = 0\n",
                "        total = 0\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            for imgs, labels in val_loader:\n",
                "                imgs, labels = imgs.to(device), labels.to(device)\n",
                "                salidas = modelo(imgs)\n",
                "                loss = criterio(salidas, labels)\n",
                "                \n",
                "                val_loss += loss.item()\n",
                "                _, pred = torch.max(salidas, 1)\n",
                "                correctos += (pred == labels).sum().item()\n",
                "                total += labels.size(0)\n",
                "        \n",
                "        val_loss = val_loss / len(val_loader)\n",
                "        val_acc = 100 * correctos / total\n",
                "        \n",
                "        # Guardamos en el historial\n",
                "        hist_train_loss.append(train_loss)\n",
                "        hist_val_loss.append(val_loss)\n",
                "        hist_train_acc.append(train_acc)\n",
                "        hist_val_acc.append(val_acc)\n",
                "        \n",
                "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.1f}% | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.1f}%\")\n",
                "    \n",
                "    return hist_train_loss, hist_val_loss, hist_train_acc, hist_val_acc"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Entrenamos la CNN desde cero"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Parametros\n",
                "EPOCHS = 15\n",
                "BATCH_SIZE = 16\n",
                "LEARNING_RATE = 0.001\n",
                "SEMILLA = 42\n",
                "\n",
                "# Fijamos semilla y cargamos datos\n",
                "fijar_semilla(SEMILLA)\n",
                "train_loader, val_loader, num_clases = cargar_datos(BATCH_SIZE, SEMILLA)\n",
                "\n",
                "# Creamos el modelo\n",
                "modelo_cnn = MiCNN(num_clases).to(device)\n",
                "print(\"\\nArquitectura de mi CNN:\")\n",
                "print(modelo_cnn)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Entrenamos\n",
                "print(\"Entrenando CNN desde cero...\")\n",
                "hist_cnn = entrenar(modelo_cnn, train_loader, val_loader, EPOCHS, LEARNING_RATE)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Graficamos las curvas de la CNN"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 4))\n",
                "\n",
                "# Curva de perdida\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(hist_cnn[0], label='Train')\n",
                "plt.plot(hist_cnn[1], label='Val')\n",
                "plt.title('Perdida - CNN desde cero')\n",
                "plt.xlabel('Epoca')\n",
                "plt.ylabel('Loss')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "\n",
                "# Curva de accuracy\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(hist_cnn[2], label='Train')\n",
                "plt.plot(hist_cnn[3], label='Val')\n",
                "plt.title('Accuracy - CNN desde cero')\n",
                "plt.xlabel('Epoca')\n",
                "plt.ylabel('Accuracy %')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('curvas_cnn.png')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explicacion de las curvas de la CNN\n",
                "\n",
                "**Grafica de Perdida (izquierda):**\n",
                "- La linea azul (Train) baja rapidamente desde 1.0 hasta casi 0. Esto significa que el modelo esta aprendiendo bien con los datos de entrenamiento.\n",
                "- La linea naranja (Val) baja al principio pero despues empieza a subir. Esto indica **overfitting**: el modelo memoriza los datos de entrenamiento pero no generaliza bien a datos nuevos.\n",
                "\n",
                "**Grafica de Accuracy (derecha):**\n",
                "- El accuracy de entrenamiento (azul) llega al 100%, confirmando que el modelo memorizo los datos de train.\n",
                "- El accuracy de validacion (naranja) se queda alrededor del 90% con algunas subidas y bajadas.\n",
                "\n",
                "**Que significa esto:** Hay overfitting porque la perdida de validacion sube mientras la de entrenamiento baja. Esto es normal cuando tenemos pocas imagenes (solo 78 en nuestro caso)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PARTE B: TRANSFER LEARNING\n",
                "\n",
                "**Contenido:**\n",
                "5. Modelo preentrenado: ResNet18\n",
                "6. Configuracion: Reemplazo de capa final + congelacion de capas conv\n",
                "7. Entrenamiento con mismo dataset y condiciones similares"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5 y 6. Creamos el modelo con Transfer Learning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def crear_modelo_transfer(num_clases):\n",
                "    # Cargamos ResNet18 ya entrenado\n",
                "    modelo = models.resnet18(pretrained=True)\n",
                "    \n",
                "    # Congelamos todas las capas (no se van a entrenar)\n",
                "    for param in modelo.parameters():\n",
                "        param.requires_grad = False\n",
                "    \n",
                "    # Cambiamos solo la ultima capa para nuestras 3 clases\n",
                "    modelo.fc = nn.Linear(modelo.fc.in_features, num_clases)\n",
                "    \n",
                "    return modelo"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7. Entrenamos con Transfer Learning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fijamos semilla y cargamos datos (igual que antes)\n",
                "fijar_semilla(SEMILLA)\n",
                "train_loader, val_loader, num_clases = cargar_datos(BATCH_SIZE, SEMILLA)\n",
                "\n",
                "# Creamos el modelo con transfer learning\n",
                "modelo_transfer = crear_modelo_transfer(num_clases).to(device)\n",
                "print(\"Modelo Transfer Learning creado\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Entrenamos (solo la ultima capa)\n",
                "print(\"Entrenando con Transfer Learning...\")\n",
                "hist_transfer = entrenar(modelo_transfer, train_loader, val_loader, EPOCHS, LEARNING_RATE)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Graficamos las curvas del Transfer Learning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 4))\n",
                "\n",
                "# Curva de perdida\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(hist_transfer[0], label='Train')\n",
                "plt.plot(hist_transfer[1], label='Val')\n",
                "plt.title('Perdida - Transfer Learning')\n",
                "plt.xlabel('Epoca')\n",
                "plt.ylabel('Loss')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "\n",
                "# Curva de accuracy\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(hist_transfer[2], label='Train')\n",
                "plt.plot(hist_transfer[3], label='Val')\n",
                "plt.title('Accuracy - Transfer Learning')\n",
                "plt.xlabel('Epoca')\n",
                "plt.ylabel('Accuracy %')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('curvas_transfer.png')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explicacion de las curvas del Transfer Learning\n",
                "\n",
                "**Comparando con la CNN desde cero:**\n",
                "- El Transfer Learning generalmente muestra curvas mas estables\n",
                "- La diferencia entre Train y Val es menor, indicando menos overfitting\n",
                "- El modelo alcanza buen accuracy mas rapido porque ya sabe reconocer caracteristicas basicas"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PARTE C: COMPARACION Y REPRODUCIBILIDAD\n",
                "\n",
                "**Contenido:**\n",
                "8. Comparacion directa: Desempeño, velocidad de convergencia, estabilidad\n",
                "9. Reproducibilidad: Semilla fija, multiples ejecuciones\n",
                "10. Tabla comparativa\n",
                "11. Conclusion reflexiva"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 8. Comparacion de ambos modelos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Comparamos las curvas\n",
                "plt.figure(figsize=(12, 4))\n",
                "\n",
                "# Perdida\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(hist_cnn[1], label='CNN desde cero', marker='o')\n",
                "plt.plot(hist_transfer[1], label='Transfer Learning', marker='s')\n",
                "plt.title('Comparacion - Perdida de Validacion')\n",
                "plt.xlabel('Epoca')\n",
                "plt.ylabel('Loss')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "\n",
                "# Accuracy\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(hist_cnn[3], label='CNN desde cero', marker='o')\n",
                "plt.plot(hist_transfer[3], label='Transfer Learning', marker='s')\n",
                "plt.title('Comparacion - Accuracy de Validacion')\n",
                "plt.xlabel('Epoca')\n",
                "plt.ylabel('Accuracy %')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('comparacion_modelos.png')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 9. Test de reproducibilidad"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"TEST DE REPRODUCIBILIDAD\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "# Corremos 2 veces con la misma semilla\n",
                "print(\"\\nMisma semilla (42) - 2 ejecuciones:\")\n",
                "for i in range(2):\n",
                "    fijar_semilla(42)\n",
                "    train_loader, val_loader, num_clases = cargar_datos(16, 42)\n",
                "    modelo_test = MiCNN(num_clases).to(device)\n",
                "    hist = entrenar(modelo_test, train_loader, val_loader, 5, 0.001)\n",
                "    print(f\"  Ejecucion {i+1}: Mejor accuracy = {max(hist[3]):.2f}%\")\n",
                "\n",
                "# Corremos con semilla diferente\n",
                "print(\"\\nSemilla diferente (123):\")\n",
                "fijar_semilla(123)\n",
                "train_loader, val_loader, num_clases = cargar_datos(16, 123)\n",
                "modelo_test = MiCNN(num_clases).to(device)\n",
                "hist = entrenar(modelo_test, train_loader, val_loader, 5, 0.001)\n",
                "print(f\"  Ejecucion 1: Mejor accuracy = {max(hist[3]):.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explicacion de reproducibilidad\n",
                "\n",
                "- **Con la misma semilla**: Ambas ejecuciones dan el mismo resultado. Esto es importante porque significa que podemos repetir el experimento y obtener los mismos numeros.\n",
                "- **Con semilla diferente**: El resultado cambia un poco porque los datos se dividen diferente y los pesos iniciales son otros."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 10. Tabla comparativa"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"TABLA COMPARATIVA DE RESULTADOS\")\n",
                "print(\"=\"*60)\n",
                "print(f\"{'Modelo':<25} {'Val Acc Final':<15} {'Mejor Val Acc':<15}\")\n",
                "print(\"-\"*60)\n",
                "print(f\"{'CNN desde cero':<25} {hist_cnn[3][-1]:.2f}%{'':<9} {max(hist_cnn[3]):.2f}%\")\n",
                "print(f\"{'Transfer Learning':<25} {hist_transfer[3][-1]:.2f}%{'':<9} {max(hist_transfer[3]):.2f}%\")\n",
                "print(\"-\"*60)\n",
                "print(f\"\\nHiperparametros usados:\")\n",
                "print(f\"  - Learning rate: {LEARNING_RATE}\")\n",
                "print(f\"  - Batch size: {BATCH_SIZE}\")\n",
                "print(f\"  - Epochs: {EPOCHS}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 11. Conclusion reflexiva"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "Despues de hacer los experimentos y comparar ambos modelos, puedo concluir lo siguiente:\n",
                "\n",
                "**¿En que caso conviene usar Transfer Learning?**\n",
                "\n",
                "Conviene usar Transfer Learning cuando tenemos pocas imagenes, como en mi caso que solo tengo 78 fotos de bananas. El modelo preentrenado ya aprendio a reconocer formas y texturas basicas con millones de imagenes, entonces solo necesita aprender las diferencias entre mis clases.\n",
                "\n",
                "**¿Que ventajas ofrece frente al entrenamiento desde cero?**\n",
                "\n",
                "1. Aprende mas rapido porque ya tiene conocimiento previo\n",
                "2. Funciona mejor con pocos datos\n",
                "3. Es mas facil de entrenar porque solo entrenamos la ultima capa\n",
                "4. Generalmente da mejores resultados\n",
                "\n",
                "**¿Que riesgos existen si el dominio del dataset es muy diferente?**\n",
                "\n",
                "Si usamos un modelo entrenado con fotos normales para algo muy diferente (como imagenes medicas o satelitales), puede que no funcione bien. Esto es porque las caracteristicas que aprendio no son utiles para el nuevo problema. En esos casos es mejor entrenar desde cero o buscar un modelo preentrenado en imagenes similares.\n",
                "\n",
                "**En resumen**, para mi proyecto de clasificar bananas el Transfer Learning funciono mejor que entrenar la CNN desde cero, ya que con pocas imagenes logro aprender a distinguir entre bananas normales, dañadas y muy dañadas."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"PROYECTO TERMINADO\")\n",
                "print(\"=\"*50)\n",
                "print(\"Imagenes guardadas:\")\n",
                "print(\"  - curvas_cnn.png\")\n",
                "print(\"  - curvas_transfer.png\")\n",
                "print(\"  - comparacion_modelos.png\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}